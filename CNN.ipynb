{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOROS9CLJ19LTh5zJAZ7u8C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianellis1997/Sarcasm_Detection/blob/Lindsey/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtsYYXm9Ai-8",
        "outputId": "2623afc2-ffb4-47ff-cba1-4fd2120ba537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sarcasm_Detection'...\n",
            "remote: Enumerating objects: 197, done.\u001b[K\n",
            "remote: Counting objects: 100% (194/194), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 197 (delta 109), reused 115 (delta 62), pack-reused 3\u001b[K\n",
            "Receiving objects: 100% (197/197), 4.36 MiB | 16.18 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/brianellis1997/Sarcasm_Detection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbMXxrJhAzzx",
        "outputId": "7910c044-50fc-4538-b64b-d146d6f94e8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_bal = pd.read_csv('/content/drive/MyDrive/Sarcasm_Data/train_bal_2.csv')"
      ],
      "metadata": {
        "id": "fgv65YZHBDFG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_bal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iT15Bp3uCG6b",
        "outputId": "7a0ca7f1-433a-4586-9918-134d46ef8759"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0  label                                            comment  \\\n",
              "0           522142      0  I personally wasn't a huge Garrosh fan, I've a...   \n",
              "1           907864      1                                     you forgot the   \n",
              "2           604170      1                 Nah man, she's clearly an ad carry   \n",
              "3           110635      1                            This sub in a nutshell.   \n",
              "4           997758      0                                       Yes... I do.   \n",
              "...            ...    ...                                                ...   \n",
              "808613      368312      1                 Yeah, all asians are smart, right?   \n",
              "808614      541588      1                                  Nah I was serious   \n",
              "808615      833824      0  you are assuming way too much there is no liab...   \n",
              "808616       55102      1  But Planned Parenthood is the devil and must b...   \n",
              "808617      213871      0     Some people have more than 1 TB of data though   \n",
              "\n",
              "                author        subreddit  score  ups  downs        date  \\\n",
              "0          cromemako83        AskReddit      2    2      0  2015-07-01   \n",
              "1          _SharkWeek_        AskReddit      1    1      0  2013-03-01   \n",
              "2            jdswift13  leagueoflegends      1    1      0  2015-10-01   \n",
              "3            trickz-M-  GlobalOffensive      1   -1     -1  2016-12-01   \n",
              "4            guriboysf           videos      4    4      0  2010-01-01   \n",
              "...                ...              ...    ...  ...    ...         ...   \n",
              "808613        est1roth           europe      2    2      0  2016-04-01   \n",
              "808614       SrrBrrGrr            funny     -5   -5      0  2015-08-01   \n",
              "808615             cqm             blog      1    1      0  2014-09-01   \n",
              "808616  DrScientist812        worldnews      3    3      0  2016-09-01   \n",
              "808617      maliciousa              mac      1    1      0  2016-05-01   \n",
              "\n",
              "                created_utc  \\\n",
              "0       2015-07-11 01:55:53   \n",
              "1       2013-03-14 03:03:46   \n",
              "2       2015-10-21 23:22:17   \n",
              "3       2016-12-05 03:50:18   \n",
              "4       2010-01-17 21:32:40   \n",
              "...                     ...   \n",
              "808613  2016-04-17 00:05:51   \n",
              "808614  2015-08-11 23:15:11   \n",
              "808615  2014-09-30 21:44:06   \n",
              "808616  2016-09-06 12:40:25   \n",
              "808617  2016-05-23 03:23:59   \n",
              "\n",
              "                                           parent_comment  exclamation_count  \\\n",
              "0       Fuck Vol'jin. Garrosh Hellscream did nothing w...                  0   \n",
              "1       That's a lie fed to you by the LIEberal media....                  0   \n",
              "2                                       she isnt already?                  0   \n",
              "3                 Cloud 9 Qualify! (ONLY C9 FANS ALLOWED(                  0   \n",
              "4                       \"so, i hear you have a fat cock.\"                  0   \n",
              "...                                                   ...                ...   \n",
              "808613   Well if an asian woman says it, it must be true.                  0   \n",
              "808614  I don't think people understand you were jokin...                  0   \n",
              "808615  They're not saying it is easy. In fact they we...                  0   \n",
              "808616  Fall in ovarian cancer deaths worldwide linked...                  1   \n",
              "808617  I didn't watch the youtube video, but judging ...                  0   \n",
              "\n",
              "        questionmark_count  period_count  space_count  slash_count  \\\n",
              "0                        0             1            0            0   \n",
              "1                        0             0            0            0   \n",
              "2                        0             0            0            0   \n",
              "3                        0             1            0            0   \n",
              "4                        0             4            0            0   \n",
              "...                    ...           ...          ...          ...   \n",
              "808613                   1             0            0            0   \n",
              "808614                   0             0            0            0   \n",
              "808615                   0             0            0            0   \n",
              "808616                   0             0            0            0   \n",
              "808617                   0             0            0            0   \n",
              "\n",
              "        elips_count  capital_letters_count  word_count  total_punctuation  \n",
              "0                 0                      5          14                  4  \n",
              "1                 0                      0           3                  0  \n",
              "2                 0                      1           7                  2  \n",
              "3                 0                      1           5                  1  \n",
              "4                 0                      2           3                  4  \n",
              "...             ...                    ...         ...                ...  \n",
              "808613            0                      1           6                  3  \n",
              "808614            0                      2           4                  0  \n",
              "808615            0                      0          41                  6  \n",
              "808616            0                      3          13                  1  \n",
              "808617            0                      3          10                  0  \n",
              "\n",
              "[808618 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5245e476-ec23-4745-9006-7bfc45602b2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>comment</th>\n",
              "      <th>author</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>score</th>\n",
              "      <th>ups</th>\n",
              "      <th>downs</th>\n",
              "      <th>date</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>parent_comment</th>\n",
              "      <th>exclamation_count</th>\n",
              "      <th>questionmark_count</th>\n",
              "      <th>period_count</th>\n",
              "      <th>space_count</th>\n",
              "      <th>slash_count</th>\n",
              "      <th>elips_count</th>\n",
              "      <th>capital_letters_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>total_punctuation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>522142</td>\n",
              "      <td>0</td>\n",
              "      <td>I personally wasn't a huge Garrosh fan, I've a...</td>\n",
              "      <td>cromemako83</td>\n",
              "      <td>AskReddit</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-07-01</td>\n",
              "      <td>2015-07-11 01:55:53</td>\n",
              "      <td>Fuck Vol'jin. Garrosh Hellscream did nothing w...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>907864</td>\n",
              "      <td>1</td>\n",
              "      <td>you forgot the</td>\n",
              "      <td>_SharkWeek_</td>\n",
              "      <td>AskReddit</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2013-03-01</td>\n",
              "      <td>2013-03-14 03:03:46</td>\n",
              "      <td>That's a lie fed to you by the LIEberal media....</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>604170</td>\n",
              "      <td>1</td>\n",
              "      <td>Nah man, she's clearly an ad carry</td>\n",
              "      <td>jdswift13</td>\n",
              "      <td>leagueoflegends</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-10-01</td>\n",
              "      <td>2015-10-21 23:22:17</td>\n",
              "      <td>she isnt already?</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>110635</td>\n",
              "      <td>1</td>\n",
              "      <td>This sub in a nutshell.</td>\n",
              "      <td>trickz-M-</td>\n",
              "      <td>GlobalOffensive</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-12-01</td>\n",
              "      <td>2016-12-05 03:50:18</td>\n",
              "      <td>Cloud 9 Qualify! (ONLY C9 FANS ALLOWED(</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>997758</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes... I do.</td>\n",
              "      <td>guriboysf</td>\n",
              "      <td>videos</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-01</td>\n",
              "      <td>2010-01-17 21:32:40</td>\n",
              "      <td>\"so, i hear you have a fat cock.\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808613</th>\n",
              "      <td>368312</td>\n",
              "      <td>1</td>\n",
              "      <td>Yeah, all asians are smart, right?</td>\n",
              "      <td>est1roth</td>\n",
              "      <td>europe</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-04-01</td>\n",
              "      <td>2016-04-17 00:05:51</td>\n",
              "      <td>Well if an asian woman says it, it must be true.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808614</th>\n",
              "      <td>541588</td>\n",
              "      <td>1</td>\n",
              "      <td>Nah I was serious</td>\n",
              "      <td>SrrBrrGrr</td>\n",
              "      <td>funny</td>\n",
              "      <td>-5</td>\n",
              "      <td>-5</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-08-01</td>\n",
              "      <td>2015-08-11 23:15:11</td>\n",
              "      <td>I don't think people understand you were jokin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808615</th>\n",
              "      <td>833824</td>\n",
              "      <td>0</td>\n",
              "      <td>you are assuming way too much there is no liab...</td>\n",
              "      <td>cqm</td>\n",
              "      <td>blog</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2014-09-01</td>\n",
              "      <td>2014-09-30 21:44:06</td>\n",
              "      <td>They're not saying it is easy. In fact they we...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808616</th>\n",
              "      <td>55102</td>\n",
              "      <td>1</td>\n",
              "      <td>But Planned Parenthood is the devil and must b...</td>\n",
              "      <td>DrScientist812</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-09-01</td>\n",
              "      <td>2016-09-06 12:40:25</td>\n",
              "      <td>Fall in ovarian cancer deaths worldwide linked...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808617</th>\n",
              "      <td>213871</td>\n",
              "      <td>0</td>\n",
              "      <td>Some people have more than 1 TB of data though</td>\n",
              "      <td>maliciousa</td>\n",
              "      <td>mac</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-01</td>\n",
              "      <td>2016-05-23 03:23:59</td>\n",
              "      <td>I didn't watch the youtube video, but judging ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>808618 rows × 20 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5245e476-ec23-4745-9006-7bfc45602b2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5245e476-ec23-4745-9006-7bfc45602b2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5245e476-ec23-4745-9006-7bfc45602b2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-454dfee8-69f0-4f86-86a5-aaf4a117859d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-454dfee8-69f0-4f86-86a5-aaf4a117859d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-454dfee8-69f0-4f86-86a5-aaf4a117859d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b55facf9-1f2d-4d97-8ace-6170c54d6fb7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_bal')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b55facf9-1f2d-4d97-8ace-6170c54d6fb7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_bal');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_bal"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, string, time, nltk\n",
        "import numpy as np\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords as stopwordprovider\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iADH_DTECJ5E",
        "outputId": "95e5171c-6805-4570-c646-bdee499d3c42"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_bal.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaHf2cjiCmOd",
        "outputId": "7d9c1355-7257-4a50-ec4f-9bb4eedc028a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 808618 entries, 0 to 808617\n",
            "Data columns (total 20 columns):\n",
            " #   Column                 Non-Null Count   Dtype \n",
            "---  ------                 --------------   ----- \n",
            " 0   Unnamed: 0             808618 non-null  int64 \n",
            " 1   label                  808618 non-null  int64 \n",
            " 2   comment                808618 non-null  object\n",
            " 3   author                 808618 non-null  object\n",
            " 4   subreddit              808618 non-null  object\n",
            " 5   score                  808618 non-null  int64 \n",
            " 6   ups                    808618 non-null  int64 \n",
            " 7   downs                  808618 non-null  int64 \n",
            " 8   date                   808618 non-null  object\n",
            " 9   created_utc            808618 non-null  object\n",
            " 10  parent_comment         808618 non-null  object\n",
            " 11  exclamation_count      808618 non-null  int64 \n",
            " 12  questionmark_count     808618 non-null  int64 \n",
            " 13  period_count           808618 non-null  int64 \n",
            " 14  space_count            808618 non-null  int64 \n",
            " 15  slash_count            808618 non-null  int64 \n",
            " 16  elips_count            808618 non-null  int64 \n",
            " 17  capital_letters_count  808618 non-null  int64 \n",
            " 18  word_count             808618 non-null  int64 \n",
            " 19  total_punctuation      808618 non-null  int64 \n",
            "dtypes: int64(14), object(6)\n",
            "memory usage: 123.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = train_bal['label']\n",
        "X = train_bal.drop(columns=['label'])"
      ],
      "metadata": {
        "id": "lPn8BNwCIKOu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ],
      "metadata": {
        "id": "t8zGxd5oHyaq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL3A3XdTPtlQ",
        "outputId": "ea686693-e0ca-47d0-efde-94a824722d28"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "646894"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbIFZJzXP0NO",
        "outputId": "a1c0533f-84a3-4197-db0a-4c4dff62a2a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "646894"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_text = X_train[['comment', 'parent_comment']]\n",
        "X_numeric = X_train[['word_count', 'capital_letters_count', 'total_punctuation', 'score']] # add brians feature engineering"
      ],
      "metadata": {
        "id": "A7fWClefDnS7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_numeric.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf5xr8wmP7VU",
        "outputId": "5606fec7-39c9-45bc-d893-e174a51a33c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "646894"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_text.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hkhJcjtRiO3",
        "outputId": "d1609b71-468b-45a5-db95-4cf5e7aa7b6e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "646894"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 10000  # Maximum number of words to keep based on word frequency\n",
        "max_seq_length = 100  # Maximum length of sequences"
      ],
      "metadata": {
        "id": "Xv1CbJ_JECdP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, concatenate, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_text['comment'] + ' ' + X_text['parent_comment'])"
      ],
      "metadata": {
        "id": "vkKhwNpGEVpo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_text_comment_seq = tokenizer.texts_to_sequences(X_text['comment'])\n",
        "X_text_parent_comment_seq = tokenizer.texts_to_sequences(X_text['parent_comment'])"
      ],
      "metadata": {
        "id": "8U6rSQhHE19Y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_text_parent_comment_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AxTFnVeQDNG",
        "outputId": "631ec23a-887c-4cab-b9fb-296aef1a8715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "646894"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_text_comment_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMGYmmYqR_sZ",
        "outputId": "cb3627ac-102b-4d5b-a002-88cbc01e8bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "646894"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvJsrq5lSDR4",
        "outputId": "fe778969-88ce-40f0-ae87-b8d800bb010a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "646894"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_text_comment_pad = pad_sequences(X_text_comment_seq, maxlen=max_seq_length)\n",
        "X_text_parent_comment_pad = pad_sequences(X_text_parent_comment_seq, maxlen=max_seq_length)"
      ],
      "metadata": {
        "id": "AWS2YuvXFO2o"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_text_comment_pad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNkXrtVvSO8A",
        "outputId": "737e845a-7305-4bac-a58e-2692cd646a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "646894"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_text_parent_comment_pad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o-27OYcSTtN",
        "outputId": "1fe173d8-5163-40e9-e442-f8fc6bfad3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "646894"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_numeric_scaled = scaler.fit_transform(X_numeric)"
      ],
      "metadata": {
        "id": "PsZ11UoIGxPm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_numeric_scaled.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m3kK7NyKNEv",
        "outputId": "aba3f37f-74ad-4033-bcf2-ea0f3eea882e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "646894"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pretrained word2vec model"
      ],
      "metadata": {
        "id": "vToKMYEOrzSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.phrases import Phraser, Phrases\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "word2vec = gensim.models.Word2Vec.load('/content/drive/MyDrive/Sarcasm_Data/word2vec.model')"
      ],
      "metadata": {
        "id": "PimYeb7fr10c"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words = word2vec.wv.most_similar('ok')\n",
        "similar_words"
      ],
      "metadata": {
        "id": "tOYksVAZsI2L",
        "outputId": "7347af6c-928e-4d09-e15a-dea473bef18a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('okay', 0.9446449279785156),\n",
              " ('OK', 0.9253052473068237),\n",
              " ('alright', 0.7982171773910522),\n",
              " ('fine', 0.6672182083129883),\n",
              " ('perfectly_fine', 0.642020046710968),\n",
              " ('cool', 0.5878971815109253),\n",
              " ('justified', 0.5626591444015503),\n",
              " ('wrong', 0.5318138599395752),\n",
              " ('understandable', 0.5288909077644348),\n",
              " ('unacceptable', 0.4947114884853363)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "word_index = {word: idx for idx, word in enumerate(word2vec.wv.index_to_key, start=1)}\n"
      ],
      "metadata": {
        "id": "rHyHDGozvsrs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.layers import Embedding\n",
        "\n",
        "# Assume word2vec is your pre-trained Word2Vec model\n",
        "# Assume word_index is a dictionary mapping from word to integer index\n",
        "# Assume max_words is the size of your vocabulary, and word2vec.vector_size is the size of each word vector\n",
        "\n",
        "embedding_dim = word2vec.vector_size\n",
        "max_words = len(word_index) + 1  # Adjust based on whether you start indexing from 0 or 1\n",
        "\n",
        "# Initialize the embedding matrix\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "\n",
        "# Populate the embedding matrix\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        if word in word2vec.wv:\n",
        "            # Words not found in the embedding index will be all zeros\n",
        "            embedding_matrix[i] = word2vec.wv[word]\n",
        "\n"
      ],
      "metadata": {
        "id": "9L0nq3qru1Up"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim"
      ],
      "metadata": {
        "id": "CGmd2iDQw-nf",
        "outputId": "ba72cece-9526-4844-feb1-3f9abba9e8ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN Model1"
      ],
      "metadata": {
        "id": "N85IjdJow5tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, concatenate, Dropout\n",
        "# from keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "# # tune pooling size\n",
        "# pool_size = 2\n",
        "\n",
        "# # smaller batch size for memory purposes\n",
        "# batch_size = 32\n",
        "\n",
        "# # Three model inputs so far\n",
        "# comment_input = Input(shape=(max_seq_length,), name='comment_input')\n",
        "# parent_comment_input = Input(shape=(max_seq_length,), name='parent_comment_input')\n",
        "# numeric_input = Input(shape=(X_numeric_scaled.shape[1],), name='numeric_input')\n",
        "\n",
        "# embedding_dim = 100\n",
        "# num_filters = 128\n",
        "# filter_sizes = [3, 4, 5]\n",
        "\n",
        "# embedding_layer = Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_seq_length)\n",
        "# comment_embedding = embedding_layer(comment_input)\n",
        "# parent_comment_embedding = embedding_layer(parent_comment_input)\n",
        "\n",
        "# conv_blocks = []\n",
        "# for filter_size in filter_sizes:\n",
        "#     conv_comment = Conv1D(filters=num_filters,\n",
        "#                           kernel_size=filter_size,\n",
        "#                           padding='valid',\n",
        "#                           activation='relu',\n",
        "#                           strides=1)(comment_embedding)\n",
        "#     conv_parent_comment = Conv1D(filters=num_filters,\n",
        "#                                  kernel_size=filter_size,\n",
        "#                                  padding='valid',\n",
        "#                                  activation='relu',\n",
        "#                                  strides=1)(parent_comment_embedding)\n",
        "\n",
        "#     max_pool_comment = MaxPooling1D(pool_size=max_seq_length - filter_size + 1)(conv_comment)\n",
        "#     max_pool_parent_comment = MaxPooling1D(pool_size=max_seq_length - filter_size + 1)(conv_parent_comment)\n",
        "\n",
        "#     conv_blocks.append(max_pool_comment)\n",
        "#     conv_blocks.append(max_pool_parent_comment)\n",
        "\n",
        "\n",
        "# # numeric_dense = Dense(64, activation='relu')(numeric_input)\n",
        "# # numeric_dense = Dense(32, activation='relu')(numeric_dense)\n",
        "\n",
        "\n",
        "# flatten_tensors = [Flatten()(tensor) for tensor in conv_blocks]\n",
        "\n",
        "\n",
        "# numeric_dense = Dense(64, activation='relu')(numeric_input)\n",
        "# numeric_dense = Dropout(0.5)(numeric_dense)\n",
        "# numeric_dense = Dense(32, activation='relu')(numeric_dense)\n",
        "\n",
        "\n",
        "\n",
        "# concatenated_final = concatenate(flatten_tensors + [numeric_dense], axis=-1)\n",
        "\n",
        "\n",
        "# dense = Dense(128, activation='relu')(concatenated_final)\n",
        "# dense = Dropout(0.5)(dense)\n",
        "# output = Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "\n",
        "# model1 = Model(inputs=[comment_input, parent_comment_input, numeric_input], outputs=output)\n",
        "\n",
        "# model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model1.summary()\n",
        "# #plot_model(model1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9T69rpviIibk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_text_test = X_test[['comment', 'parent_comment']]\n",
        "X_numeric_test = X_test[['word_count', 'capital_letters_count', 'total_punctuation']] # add brians feature engineering"
      ],
      "metadata": {
        "id": "mt5Xai4-OmAL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_text_comment_seq_test = tokenizer.texts_to_sequences(X_text_test['comment'])\n",
        "X_text_parent_comment_seq_test = tokenizer.texts_to_sequences(X_text_test['parent_comment'])"
      ],
      "metadata": {
        "id": "V-qXRqiUO-Cn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_text_comment_pad_test = pad_sequences(X_text_comment_seq_test, maxlen=max_seq_length)\n",
        "X_text_parent_comment_pad_test = pad_sequences(X_text_parent_comment_seq_test, maxlen=max_seq_length)"
      ],
      "metadata": {
        "id": "LahsOuvVO4KC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_numeric_scaled_test = scaler.fit_transform(X_numeric_test)"
      ],
      "metadata": {
        "id": "XnGKNL4fPPH0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFV5BsKcPfjx",
        "outputId": "0d8c5d7b-8eb0-441a-89e7-e1e01b270a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "646894"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# len(X_text_comment_pad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlptZx7eQjGo",
        "outputId": "95d0cae9-d9b8-4062-d5f1-e9af06b6acff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "646894"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model1.fit({'comment_input': X_text_comment_pad, 'parent_comment_input': X_text_parent_comment_pad, 'numeric_input': X_numeric_scaled}, y_train, epochs=4, batch_size=batch_size, validation_split=0.1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ger_pwIhLPKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss, accuracy = model1.evaluate({'comment_input': X_text_comment_pad_test,\n",
        "#                                  'parent_comment_input': X_text_parent_comment_pad_test,\n",
        "#                                  'numeric_input': X_numeric_scaled_test},\n",
        "#                                 y_test)\n",
        "\n",
        "# print(\"Test Loss:\", loss)\n",
        "# print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "0DhFcPEWLBh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "# from keras.models import Model\n",
        "\n",
        "# predictions = model1.predict({'comment_input': X_text_comment_pad_test,\n",
        "#                              'parent_comment_input': X_text_parent_comment_pad_test,\n",
        "#                              'numeric_input': X_numeric_scaled_test})\n",
        "\n",
        "# prediction_result = (predictions > 0.5).astype('int32')\n",
        "\n",
        "# accuracy = accuracy_score(y_test, prediction_result)\n",
        "# print('Accuracy: %f' % accuracy)\n",
        "\n",
        "\n",
        "# precision = precision_score(y_test, prediction_result)\n",
        "# print('Precision: %f' % precision)\n",
        "\n",
        "\n",
        "# recall = recall_score(y_test, prediction_result)\n",
        "# print('Recall: %f' % recall)\n",
        "\n",
        "\n",
        "# f1 = f1_score(y_test, prediction_result)\n",
        "# print('F1 score: %f' % f1)\n",
        "\n",
        "\n",
        "# predictions = predictions.flatten()\n",
        "# auc = roc_auc_score(y_test, predictions)\n",
        "# print('ROC AUC: %f' % auc)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R670Cps3hMmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build CNN with comment and parent comment\n"
      ],
      "metadata": {
        "id": "NF-6G-fjlMvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN Model 2"
      ],
      "metadata": {
        "id": "2RhgGU0ynmr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, concatenate, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "comment_input = Input(shape=(max_seq_length,), name='comment_input')\n",
        "parent_comment_input = Input(shape=(max_seq_length,), name='parent_comment_input')\n",
        "numeric_input = Input(shape=(X_numeric_scaled.shape[1],), name='numeric_input')\n",
        "\n",
        "embedding_layer = Embedding(input_dim=max_words,\n",
        "                            output_dim=150,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_seq_length,\n",
        "                            trainable=True)\n",
        "\n",
        "comment_embedding = embedding_layer(comment_input)\n",
        "parent_comment_embedding = embedding_layer(parent_comment_input)\n",
        "\n",
        "concatenated_embeddings = concatenate([comment_embedding, parent_comment_embedding], axis=1)\n",
        "\n",
        "conv1 = Conv1D(filters=128,\n",
        "               kernel_size=3,\n",
        "               padding='valid',\n",
        "               activation='relu',\n",
        "               strides=1)(concatenated_embeddings)\n",
        "\n",
        "max_pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "# Additional Convolutional Layer\n",
        "conv2 = Conv1D(filters=64,  # You can adjust the number of filters\n",
        "               kernel_size=3,  # Adjust the kernel size as needed\n",
        "               padding='valid',  # 'valid' or 'same'\n",
        "               activation='relu',\n",
        "               strides=1)(max_pool1)\n",
        "\n",
        "\n",
        "dropout1 = Dropout(0.5)(conv2)\n",
        "\n",
        "\n",
        "flattened = Flatten()(dropout1)\n",
        "max_dense1 = Dense(128, activation='relu')(flattened)\n",
        "\n",
        "numeric_dense = Dense(64, activation='relu')(numeric_input)\n",
        "numeric_dense = Dropout(0.5)(numeric_dense)\n",
        "numeric_dense = Dense(32, activation='relu')(numeric_dense)\n",
        "\n",
        "\n",
        "concatenated_final = concatenate([max_dense1, numeric_dense], axis=-1)\n",
        "\n",
        "dense = Dense(128, activation='relu')(concatenated_final)\n",
        "dropout_final = Dropout(0.5)(dense)\n",
        "output = Dense(1, activation='sigmoid')(dropout_final)\n",
        "\n",
        "model3 = Model(inputs=[comment_input, parent_comment_input, numeric_input], outputs=output)\n",
        "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "Mz3ZFxfzSna8",
        "outputId": "02876074-a08c-4077-ec42-9b62dc55aca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " comment_input (InputLayer)  [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " parent_comment_input (Inpu  [(None, 100)]                0         []                            \n",
            " tLayer)                                                                                          \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 100, 150)             4709250   ['comment_input[0][0]',       \n",
            "                                                                     'parent_comment_input[0][0]']\n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 200, 150)             0         ['embedding_1[0][0]',         \n",
            "                                                                     'embedding_1[1][0]']         \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 198, 128)             57728     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1  (None, 99, 128)              0         ['conv1d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 97, 64)               24640     ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " numeric_input (InputLayer)  [(None, 4)]                  0         []                            \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 97, 64)               0         ['conv1d_1[0][0]']            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   320       ['numeric_input[0][0]']       \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 6208)                 0         ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 64)                   0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  794752    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 32)                   2080      ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 160)                  0         ['dense[0][0]',               \n",
            " )                                                                   'dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 128)                  20608     ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 128)                  0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 1)                    129       ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5609507 (21.40 MB)\n",
            "Trainable params: 5609507 (21.40 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model3.fit({'comment_input': X_text_comment_pad, 'parent_comment_input': X_text_parent_comment_pad, 'numeric_input': X_numeric_scaled}, y_train, epochs=5, batch_size=batch_size, validation_split=0.1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GEF9urn5rlAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "# from keras.models import Model\n",
        "\n",
        "# predictions = model3.predict({'comment_input': X_text_comment_pad_test,\n",
        "#                              'parent_comment_input': X_text_parent_comment_pad_test,\n",
        "#                              'numeric_input': X_numeric_scaled_test})\n",
        "\n",
        "# prediction_result = (predictions > 0.5).astype('int32')\n",
        "\n",
        "# accuracy = accuracy_score(y_test, prediction_result)\n",
        "# print('Accuracy: %f' % accuracy)\n",
        "\n",
        "\n",
        "# precision = precision_score(y_test, prediction_result)\n",
        "# print('Precision: %f' % precision)\n",
        "\n",
        "\n",
        "# recall = recall_score(y_test, prediction_result)\n",
        "# print('Recall: %f' % recall)\n",
        "\n",
        "\n",
        "# f1 = f1_score(y_test, prediction_result)\n",
        "# print('F1 score: %f' % f1)\n",
        "\n",
        "\n",
        "# predictions = predictions.flatten()\n",
        "# auc = roc_auc_score(y_test, predictions)\n",
        "# print('ROC AUC: %f' % auc)\n"
      ],
      "metadata": {
        "id": "H_ey9kO2tJt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, concatenate, Dropout, Bidirectional, LSTM, BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "comment_input = Input(shape=(max_seq_length,), name='comment_input')\n",
        "parent_comment_input = Input(shape=(max_seq_length,), name='parent_comment_input')\n",
        "numeric_input = Input(shape=(X_numeric_scaled.shape[1],), name='numeric_input')\n",
        "\n",
        "embedding_layer = Embedding(input_dim=max_words, output_dim=150, weights=[embedding_matrix], input_length=max_seq_length, trainable=True)\n",
        "\n",
        "comment_embedding = embedding_layer(comment_input)\n",
        "parent_comment_embedding = embedding_layer(parent_comment_input)\n",
        "\n",
        "concatenated_embeddings = concatenate([comment_embedding, parent_comment_embedding], axis=1)\n",
        "\n",
        "conv1 = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(concatenated_embeddings)\n",
        "conv1 = BatchNormalization()(conv1)\n",
        "conv1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "conv2 = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')(conv1)\n",
        "conv2 = BatchNormalization()(conv2)\n",
        "conv2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "\n",
        "\n",
        "bi_lstm = Bidirectional(LSTM(64))(conv2)\n",
        "\n",
        "flattened = Flatten()(bi_lstm)\n",
        "flattened = Dropout(0.5)(flattened)\n",
        "\n",
        "\n",
        "numeric_dense = Dense(64, activation='relu')(numeric_input)\n",
        "numeric_dense = Dropout(0.5)(numeric_dense)\n",
        "numeric_dense = Dense(32, activation='relu')(numeric_dense)\n",
        "\n",
        "\n",
        "concatenated_final = concatenate([flattened, numeric_dense], axis=-1)\n",
        "\n",
        "dense1 = Dense(128, activation='relu')(concatenated_final)\n",
        "dense1 = Dropout(0.5)(dense1)\n",
        "output = Dense(1, activation='sigmoid')(dense1)\n",
        "\n",
        "model4 = Model(inputs=[comment_input, parent_comment_input, numeric_input], outputs=output)\n",
        "model4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "1dGaBoHRMBww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model4.fit({'comment_input': X_text_comment_pad, 'parent_comment_input': X_text_parent_comment_pad, 'numeric_input': X_numeric_scaled}, y_train, epochs=5, batch_size=batch_size, validation_split=0.1)"
      ],
      "metadata": {
        "id": "R-ljfHDhMSdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "# from keras.models import Model\n",
        "\n",
        "# predictions = model4.predict({'comment_input': X_text_comment_pad_test,\n",
        "#                              'parent_comment_input': X_text_parent_comment_pad_test,\n",
        "#                              'numeric_input': X_numeric_scaled_test})\n",
        "\n",
        "# prediction_result = (predictions > 0.5).astype('int32')\n",
        "\n",
        "# accuracy = accuracy_score(y_test, prediction_result)\n",
        "# print('Accuracy: %f' % accuracy)\n",
        "\n",
        "\n",
        "# precision = precision_score(y_test, prediction_result)\n",
        "# print('Precision: %f' % precision)\n",
        "\n",
        "\n",
        "# recall = recall_score(y_test, prediction_result)\n",
        "# print('Recall: %f' % recall)\n",
        "\n",
        "\n",
        "# f1 = f1_score(y_test, prediction_result)\n",
        "# print('F1 score: %f' % f1)\n",
        "\n",
        "\n",
        "# predictions = predictions.flatten()\n",
        "# auc = roc_auc_score(y_test, predictions)\n",
        "# print('ROC AUC: %f' % auc)"
      ],
      "metadata": {
        "id": "PurepsCkSdv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Still at around 70% accuracy... look into cross validation or somethhing to find optimal model\n",
        "\n"
      ],
      "metadata": {
        "id": "ZGqB4ruDtare"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner\n"
      ],
      "metadata": {
        "id": "ij-CCho5zZ_p",
        "outputId": "a06b7ec0-b59b-4b54-86d2-abc5ef15801d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, concatenate, Dropout, Bidirectional, LSTM\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from kerastuner import HyperModel\n",
        "\n",
        "def build_model(hp):\n",
        "    comment_input = Input(shape=(max_seq_length,), name='comment_input')\n",
        "    parent_comment_input = Input(shape=(max_seq_length,), name='parent_comment_input')\n",
        "    numeric_input = Input(shape=(X_numeric_scaled.shape[1],), name='numeric_input')\n",
        "\n",
        "    embedding_layer = Embedding(input_dim=max_words,\n",
        "                                output_dim=150,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=max_seq_length,\n",
        "                                trainable=True)\n",
        "\n",
        "    comment_embedding = embedding_layer(comment_input)\n",
        "    parent_comment_embedding = embedding_layer(parent_comment_input)\n",
        "\n",
        "    concatenated_embeddings = concatenate([comment_embedding, parent_comment_embedding], axis=1)\n",
        "\n",
        "    conv1 = Conv1D(filters=hp.Int('conv1_filters', min_value=32, max_value=128, step=32),\n",
        "                   kernel_size=hp.Choice('conv1_kernel_size', values=[3, 5]),\n",
        "                   padding='same',\n",
        "                   activation='relu')(concatenated_embeddings)\n",
        "    conv1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "    conv2 = Conv1D(filters=hp.Int('conv2_filters', min_value=32, max_value=64, step=32),\n",
        "                   kernel_size=hp.Choice('conv2_kernel_size', values=[3, 5]),\n",
        "                   padding='same',\n",
        "                   activation='relu')(conv1)\n",
        "    conv2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "\n",
        "    bi_lstm = Bidirectional(LSTM(hp.Int('lstm_units', min_value=32, max_value=128, step=32)))(conv2)\n",
        "\n",
        "    flattened = Flatten()(bi_lstm)\n",
        "    flattened = Dropout(0.5)(flattened)\n",
        "\n",
        "    dense = Dense(hp.Int('dense_units', min_value=64, max_value=128, step=32), activation='relu')(flattened)\n",
        "    output = Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "    model = Model(inputs=[comment_input, parent_comment_input, numeric_input], outputs=output)\n",
        "\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "BAyE5IID2Bxb",
        "outputId": "820c2c42-ea1d-46a4-813f-e9c883d97338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-eb1a0629d2de>:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner import HyperModel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='hparam_tuning'\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "tuner.search(x=[X_text_comment_pad, X_text_parent_comment_pad, X_numeric_scaled],\n",
        "             y=y_train,\n",
        "             epochs=4,\n",
        "             batch_size=128,\n",
        "             validation_split=0.10)\n",
        "\n",
        "\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n"
      ],
      "metadata": {
        "id": "jyMmLBeb2JBL",
        "outputId": "feae6381-2623-4dc3-89a8-27a7be7c9dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 7\n",
            "conv1_filters (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "conv1_kernel_size (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5], 'ordered': True}\n",
            "conv2_filters (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 64, 'step': 32, 'sampling': 'linear'}\n",
            "conv2_kernel_size (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5], 'ordered': True}\n",
            "lstm_units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "dense_units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "32                |32                |conv1_filters\n",
            "5                 |5                 |conv1_kernel_size\n",
            "64                |64                |conv2_filters\n",
            "5                 |5                 |conv2_kernel_size\n",
            "96                |96                |lstm_units\n",
            "64                |64                |dense_units\n",
            "0.01              |0.01              |learning_rate\n",
            "\n",
            "Epoch 1/4\n",
            "1370/4549 [========>.....................] - ETA: 2:15 - loss: 0.6938 - accuracy: 0.5032"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-8fef9f356208>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m tuner.search(x=[X_text_comment_pad, X_text_parent_comment_pad, X_numeric_scaled],\n\u001b[0m\u001b[1;32m     15\u001b[0m              \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    240\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Save the build config for model loading later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "# best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "# print(\"Best hyperparameters:\")\n",
        "# for hp in best_hp.values:\n",
        "#     print(f\"{hp}: {best_hp.get(hp)}\")"
      ],
      "metadata": {
        "id": "Muvx6G0zYmYw"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# best_model.save('/content/drive/MyDrive/Sarcasm_Data/best_model.h5')\n"
      ],
      "metadata": {
        "id": "tS-gsa8fWua4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "best_model = load_model('/content/drive/MyDrive/Sarcasm_Data/best_model.h5')"
      ],
      "metadata": {
        "id": "yZapMKvG_mBX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = best_model.evaluate([X_text_comment_pad_test, X_text_parent_comment_pad_test, X_numeric_scaled_test], y_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "id": "efGRwUU32fGj",
        "outputId": "36fdddd5-c418-4448-f4e8-071ec7ca779c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1917, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 2 of layer \"model\" is incompatible with the layer: expected shape=(None, 4), found shape=(None, 3)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-971f1bccd3af>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_text_comment_pad_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_text_parent_comment_pad_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_numeric_scaled_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Accuracy: {accuracy}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1917, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 2 of layer \"model\" is incompatible with the layer: expected shape=(None, 4), found shape=(None, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from keras.models import Model\n",
        "\n",
        "predictions = best_model.predict({'comment_input': X_text_comment_pad_test,\n",
        "                             'parent_comment_input': X_text_parent_comment_pad_test,\n",
        "                             'numeric_input': X_numeric_scaled_test})\n",
        "\n",
        "prediction_result = (predictions > 0.5).astype('int32')\n",
        "\n",
        "accuracy = accuracy_score(y_test, prediction_result)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "\n",
        "precision = precision_score(y_test, prediction_result)\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test, prediction_result)\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test, prediction_result)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "\n",
        "predictions = predictions.flatten()\n",
        "auc = roc_auc_score(y_test, predictions)\n",
        "print('ROC AUC: %f' % auc)"
      ],
      "metadata": {
        "id": "1hgTkx1MY-J8",
        "outputId": "828c3717-8ab7-43c2-a817-221e3bf715ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 2 of layer \"model\" is incompatible with the layer: expected shape=(None, 4), found shape=(None, 3)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-ecadfa75c313>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m predictions = best_model.predict({'comment_input': X_text_comment_pad_test,\n\u001b[0m\u001b[1;32m      5\u001b[0m                              \u001b[0;34m'parent_comment_input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_text_parent_comment_pad_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                              'numeric_input': X_numeric_scaled_test})\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 2 of layer \"model\" is incompatible with the layer: expected shape=(None, 4), found shape=(None, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model with best hyperparameters"
      ],
      "metadata": {
        "id": "rMKD_YlYZylh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Just best model with hyperparameters\n",
        "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, concatenate, Dropout, Bidirectional, LSTM, BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "comment_input = Input(shape=(max_seq_length,), name='comment_input')\n",
        "parent_comment_input = Input(shape=(max_seq_length,), name='parent_comment_input')\n",
        "numeric_input = Input(shape=(X_numeric_scaled.shape[1],), name='numeric_input')\n",
        "\n",
        "embedding_layer = Embedding(input_dim=max_words, output_dim=150, weights=[embedding_matrix], input_length=max_seq_length, trainable=True)\n",
        "\n",
        "comment_embedding = embedding_layer(comment_input)\n",
        "parent_comment_embedding = embedding_layer(parent_comment_input)\n",
        "\n",
        "concatenated_embeddings = concatenate([comment_embedding, parent_comment_embedding], axis=1)\n",
        "\n",
        "conv1 = Conv1D(filters=96, kernel_size=3, padding='same', activation='relu')(concatenated_embeddings)\n",
        "conv1 = BatchNormalization()(conv1)\n",
        "conv1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "conv2 = Conv1D(filters=64, kernel_size=5, padding='same', activation='relu')(conv1)\n",
        "conv2 = BatchNormalization()(conv2)\n",
        "conv2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "\n",
        "\n",
        "bi_lstm = Bidirectional(LSTM(64))(conv2)\n",
        "\n",
        "flattened = Flatten()(bi_lstm)\n",
        "flattened = Dropout(0.5)(flattened)\n",
        "\n",
        "\n",
        "numeric_dense = Dense(64, activation='relu')(numeric_input)\n",
        "numeric_dense = Dropout(0.5)(numeric_dense)\n",
        "numeric_dense = Dense(32, activation='relu')(numeric_dense)\n",
        "\n",
        "\n",
        "concatenated_final = concatenate([flattened, numeric_dense], axis=-1)\n",
        "\n",
        "dense1 = Dense(64, activation='relu')(concatenated_final)\n",
        "dense1 = Dropout(0.5)(dense1)\n",
        "output = Dense(1, activation='sigmoid')(dense1)\n",
        "\n",
        "model5 = Model(inputs=[comment_input, parent_comment_input, numeric_input], outputs=output)\n",
        "model5.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gBfsDqvKZ28P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.fit({'comment_input': X_text_comment_pad, 'parent_comment_input': X_text_parent_comment_pad, 'numeric_input': X_numeric_scaled}, y_train, epochs=5, batch_size=batch_size, validation_split=0.1)"
      ],
      "metadata": {
        "id": "5jRWEsWSa35S",
        "outputId": "0a0a8d85-9a35-4681-9625-14fa5e826721",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "18194/18194 [==============================] - 282s 15ms/step - loss: 0.6299 - accuracy: 0.6362 - val_loss: 0.5686 - val_accuracy: 0.7060\n",
            "Epoch 2/5\n",
            "18194/18194 [==============================] - 226s 12ms/step - loss: 0.5597 - accuracy: 0.7169 - val_loss: 0.5453 - val_accuracy: 0.7203\n",
            "Epoch 3/5\n",
            "18194/18194 [==============================] - 225s 12ms/step - loss: 0.5380 - accuracy: 0.7324 - val_loss: 0.5417 - val_accuracy: 0.7259\n",
            "Epoch 4/5\n",
            "18194/18194 [==============================] - 225s 12ms/step - loss: 0.5198 - accuracy: 0.7455 - val_loss: 0.5371 - val_accuracy: 0.7274\n",
            "Epoch 5/5\n",
            "18194/18194 [==============================] - 225s 12ms/step - loss: 0.4999 - accuracy: 0.7588 - val_loss: 0.5367 - val_accuracy: 0.7288\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a294364e4a0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from keras.models import Model\n",
        "\n",
        "predictions = model5.predict({'comment_input': X_text_comment_pad_test,\n",
        "                             'parent_comment_input': X_text_parent_comment_pad_test,\n",
        "                             'numeric_input': X_numeric_scaled_test})\n",
        "\n",
        "prediction_result = (predictions > 0.5).astype('int32')\n",
        "\n",
        "accuracy = accuracy_score(y_test, prediction_result)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "\n",
        "precision = precision_score(y_test, prediction_result)\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test, prediction_result)\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test, prediction_result)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "\n",
        "predictions = predictions.flatten()\n",
        "auc = roc_auc_score(y_test, predictions)\n",
        "print('ROC AUC: %f' % auc)"
      ],
      "metadata": {
        "id": "7RE5g-OFgefh",
        "outputId": "a7e0a2f2-4b41-414d-d2ab-fcaf23ba0ac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5054/5054 [==============================] - 20s 4ms/step\n",
            "Accuracy: 0.684432\n",
            "Precision: 0.655813\n",
            "Recall: 0.779937\n",
            "F1 score: 0.712510\n",
            "ROC AUC: 0.771780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Figure out which features to include or exclude\n",
        "#Add attention layer?\n",
        "\n",
        "#Create LSTM and Bidirectional LSTM\n"
      ],
      "metadata": {
        "id": "JQJ2fr8UGoyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean Notedbook starts here"
      ],
      "metadata": {
        "id": "Xqsf3ctJ2HEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CNN Text Covariates"
      ],
      "metadata": {
        "id": "ekJDA2kF3U_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, concatenate, Dropout, Bidirectional, LSTM\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from kerastuner import HyperModel\n",
        "\n",
        "def build_model1(hp):\n",
        "    comment_input = Input(shape=(max_seq_length,), name='comment_input')\n",
        "    parent_comment_input = Input(shape=(max_seq_length,), name='parent_comment_input')\n",
        "\n",
        "    embedding_layer = Embedding(input_dim=max_words,\n",
        "                                output_dim=150,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=max_seq_length,\n",
        "                                trainable=True)\n",
        "\n",
        "    comment_embedding = embedding_layer(comment_input)\n",
        "    parent_comment_embedding = embedding_layer(parent_comment_input)\n",
        "\n",
        "    concatenated_embeddings = concatenate([comment_embedding, parent_comment_embedding], axis=1)\n",
        "\n",
        "    conv1 = Conv1D(filters=hp.Int('conv1_filters', min_value=32, max_value=128, step=32),\n",
        "                   kernel_size=hp.Choice('conv1_kernel_size', values=[3, 5]),\n",
        "                   padding='same',\n",
        "                   activation='relu')(concatenated_embeddings)\n",
        "    conv1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "    conv2 = Conv1D(filters=hp.Int('conv2_filters', min_value=32, max_value=64, step=32),\n",
        "                   kernel_size=hp.Choice('conv2_kernel_size', values=[3, 5]),\n",
        "                   padding='same',\n",
        "                   activation='relu')(conv1)\n",
        "    conv2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "\n",
        "\n",
        "    flattened = Flatten()(conv2)\n",
        "    flattened = Dropout(0.5)(flattened)\n",
        "\n",
        "    dense = Dense(hp.Int('dense_units', min_value=64, max_value=128, step=32), activation='relu')(flattened)\n",
        "    output = Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "    model = Model(inputs=[comment_input, parent_comment_input], outputs=output)\n",
        "\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "RitW2NSh2JzX"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model1,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='hparam_tuning'\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "tuner.search(x=[X_text_comment_pad, X_text_parent_comment_pad],\n",
        "             y=y_train,\n",
        "             epochs=4,\n",
        "             batch_size=128,\n",
        "             validation_split=0.10)\n",
        "\n",
        "\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "_qSMSrNL2lYn",
        "outputId": "978a0430-01ac-41a9-ed75-b5ab69ffe92c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from my_dir/hparam_tuning/tuner0.json\n",
            "Search space summary\n",
            "Default search space size: 6\n",
            "conv1_filters (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "conv1_kernel_size (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5], 'ordered': True}\n",
            "conv2_filters (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 64, 'step': 32, 'sampling': 'linear'}\n",
            "conv2_kernel_size (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5], 'ordered': True}\n",
            "dense_units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"Best hyperparameters:\")\n",
        "for hp in best_hp.values:\n",
        "    print(f\"{hp}: {best_hp.get(hp)}\")"
      ],
      "metadata": {
        "id": "hzC4_G4b21-U",
        "outputId": "447b35a2-12b4-4a53-b10b-8a0082fd56c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:\n",
            "conv1_filters: 64\n",
            "conv1_kernel_size: 5\n",
            "conv2_filters: 64\n",
            "conv2_kernel_size: 3\n",
            "dense_units: 128\n",
            "learning_rate: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save('/content/drive/MyDrive/Sarcasm_Data/best_model.h5')"
      ],
      "metadata": {
        "id": "p6apubRr3DL4",
        "outputId": "2227cb18-c178-4280-9270-229b955c8768",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "best_model = load_model('/content/drive/MyDrive/Sarcasm_Data/best_model.h5')"
      ],
      "metadata": {
        "id": "s6r6ElId3I6p"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from keras.models import Model\n",
        "\n",
        "predictions = best_model.predict({'comment_input': X_text_comment_pad_test,\n",
        "                             'parent_comment_input': X_text_parent_comment_pad_test})\n",
        "\n",
        "prediction_result = (predictions > 0.5).astype('int32')\n",
        "\n",
        "accuracy = accuracy_score(y_test, prediction_result)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "\n",
        "precision = precision_score(y_test, prediction_result)\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test, prediction_result)\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test, prediction_result)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "\n",
        "predictions = predictions.flatten()\n",
        "auc = roc_auc_score(y_test, predictions)\n",
        "print('ROC AUC: %f' % auc)"
      ],
      "metadata": {
        "id": "pM32EKrT3PUJ",
        "outputId": "b5f5bb01-2d02-4c42-8fcd-ddba09875d8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5054/5054 [==============================] - 9s 2ms/step\n",
            "Accuracy: 0.725471\n",
            "Precision: 0.740457\n",
            "Recall: 0.696643\n",
            "F1 score: 0.717882\n",
            "ROC AUC: 0.801096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN text and non-text covariates"
      ],
      "metadata": {
        "id": "MNuQuOXb_OHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, concatenate, Dropout, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from kerastuner import HyperParameters\n",
        "\n",
        "def build_model2(hp):\n",
        "    comment_input = Input(shape=(max_seq_length,), name='comment_input')\n",
        "    parent_comment_input = Input(shape=(max_seq_length,), name='parent_comment_input')\n",
        "    numeric_input = Input(shape=(X_numeric_scaled.shape[1],), name='numeric_input')\n",
        "\n",
        "    embedding_layer = Embedding(input_dim=max_words,\n",
        "                                output_dim=150,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=max_seq_length,\n",
        "                                trainable=True)\n",
        "\n",
        "    comment_embedding = embedding_layer(comment_input)\n",
        "    parent_comment_embedding = embedding_layer(parent_comment_input)\n",
        "\n",
        "    concatenated_embeddings = concatenate([comment_embedding, parent_comment_embedding], axis=1)\n",
        "\n",
        "    conv1 = Conv1D(filters=hp.Int('conv1_filters', min_value=32, max_value=128, step=32),\n",
        "                   kernel_size=hp.Choice('conv1_kernel_size', values=[3, 5]),\n",
        "                   padding='same',\n",
        "                   activation='relu')(concatenated_embeddings)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "    conv2 = Conv1D(filters=hp.Int('conv2_filters', min_value=32, max_value=64, step=32),\n",
        "                   kernel_size=hp.Choice('conv2_kernel_size', values=[3, 5]),\n",
        "                   padding='same',\n",
        "                   activation='relu')(conv1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "\n",
        "    flattened = Flatten()(conv2)\n",
        "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
        "    flattened = Dropout(dropout_rate)(flattened)\n",
        "\n",
        "    numeric_dense_units = hp.Int('numeric_dense_units', min_value=32, max_value=128, step=32)\n",
        "    numeric_dense = Dense(numeric_dense_units, activation='relu')(numeric_input)\n",
        "    numeric_dense = Dropout(dropout_rate)(numeric_dense)\n",
        "    numeric_dense = Dense(numeric_dense_units // 2, activation='relu')(numeric_dense)\n",
        "\n",
        "    concatenated_final = concatenate([flattened, numeric_dense], axis=-1)\n",
        "\n",
        "    dense_units = hp.Int('final_dense_units', min_value=64, max_value=128, step=32)\n",
        "    dense1 = Dense(dense_units, activation='relu')(concatenated_final)\n",
        "    dense1 = Dropout(dropout_rate)(dense1)\n",
        "    output = Dense(1, activation='sigmoid')(dense1)\n",
        "\n",
        "    model = Model(inputs=[comment_input, parent_comment_input, numeric_input], outputs=output)\n",
        "\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tmYROE4-APci"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "tuner2 = RandomSearch(\n",
        "    build_model2,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='hparam_tuning'\n",
        ")\n",
        "\n",
        "tuner2.search_space_summary()\n",
        "\n",
        "tuner2.search(x=[X_text_comment_pad, X_text_parent_comment_pad,X_numeric_scaled],\n",
        "             y=y_train,\n",
        "             epochs=4,\n",
        "             batch_size=128,\n",
        "             validation_split=0.10)\n",
        "\n",
        "\n",
        "\n",
        "best_CNN_textandnontext = tuner2.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "dc4l9gjxBMoy",
        "outputId": "151060e9-5652-400f-d412-5957879d4aeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from my_dir/hparam_tuning/tuner0.json\n",
            "Search space summary\n",
            "Default search space size: 6\n",
            "conv1_filters (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "conv1_kernel_size (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5], 'ordered': True}\n",
            "conv2_filters (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 64, 'step': 32, 'sampling': 'linear'}\n",
            "conv2_kernel_size (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5], 'ordered': True}\n",
            "dense_units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Received incompatible tensor with shape (128,) when attempting to restore variable with shape (64,) and name conv1d_1/bias:0.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-60e56bf06ffb>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mbest_CNN_textandnontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36mget_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \"\"\"\n\u001b[1;32m    399\u001b[0m         \u001b[0;31m# Method only exists in this class for the docstring override.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_deepcopy_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36mget_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \"\"\"\n\u001b[1;32m    364\u001b[0m         \u001b[0mbest_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_trials\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \"\"\"\n\u001b[1;32m    364\u001b[0m         \u001b[0mbest_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_trials\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# Only load weights to avoid loading `custom_objects`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmaybe_distribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_checkpoint_fname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_restore_from_tensors\u001b[0;34m(self, restored_tensors)\u001b[0m\n\u001b[1;32m    783\u001b[0m             self.handle, self.shape, restored_tensor)\n\u001b[1;32m    784\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    786\u001b[0m             \u001b[0;34mf\"Received incompatible tensor with shape {restored_tensor.shape} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0;34mf\"when attempting to restore variable with shape {self.shape} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Received incompatible tensor with shape (128,) when attempting to restore variable with shape (64,) and name conv1d_1/bias:0."
          ]
        }
      ]
    }
  ]
}